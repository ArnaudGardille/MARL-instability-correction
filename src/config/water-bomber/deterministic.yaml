# --- Defaults ---

seed: 0
torch_deterministic: True
cuda: False
track: False
display-v-function: False
capture_video: False
save_model: True
upload_model: False
use_state: False
save_buffer: False
load_buffer: False
save_imgs: False
load_agents_from: 
load_buffer_from: 
    

    # Environment specific arguments
x_max: 4
y_max: 2
t_max: 20
n_agents: 2
env_normalization: True
num_envs: 1

    # Algorithm specific arguments
env_id: "water-bomber"
random_policy: False
no_training: False
total_timesteps: 20000
learning_rate: 0.01
buffer_size: 100000
gamma: 0.9
tau: 1.
evaluation_frequency: 1000
evaluation_episodes: 100
target_network_frequency: 100
batch_size:  1000 #2**18, #256, #
start_e: 0.99
end_e: 0.05
exploration_fraction: 0.8
learning_starts: 1000
train_frequency: 5
single_agent: False
add_id: False
add_epsilon: False
add_others_explo: False
dueling: True
deterministic_env: False
boltzmann_policy: False
loss_corrected_for_others: False
loss_not_corrected_for_priorisation: False
prio: 'td_error' #choices=['td_error', 'td-past', 'td-cur-past', 'td-cur', 'cur-past', 'cur'], default='')
rb: 'uniform' # choices=['uniform', 'prioritized', 'laber'], default='uniform',