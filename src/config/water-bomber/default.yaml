# --- Defaults ---

seed: 1
torch_deterministic: True
cuda: True
track: False
display_video: False
capture_video: False
save_model: True
upload_model: False
use_state: False
save_buffer: False
load_buffer: False
save_imgs: False
load_agents_from: 
load_buffer_from: 
    

    # Environment specific arguments
x_max: 4
y_max: 4
t_max: 20
n_agents: 2
env_normalization: True
num_envs: 1

    # Algorithm specific arguments
env_id: "water-bomber"
random_policy: False
no_training: False
total_timesteps: 200000
learning_rate: 0.001
buffer_size: 1000000
gamma: 0.99
tau: 1.
evaluation_frequency: 1000
evaluation_episodes: 100
target_network_frequency: 50
batch_size:  1000 #2**18, #256, #
start_e: 0.5
end_e: 0.05
exploration_fraction: 0.5
learning_starts: 1000
train_frequency: 100
single_agent: False
add_id: False
add_epsilon: False
add_others_explo: False
dueling: True
deterministic_env: False
boltzmann_policy: False
loss_corrected_for_others: False
loss_not_corrected_for_priorisation: False
prio: 'td_error' #choices=['td_error', 'td-past', 'td-cur-past', 'td-cur', 'cur-past', 'cur'], default='')
rb: 'uniform' # choices=['uniform', 'prioritized', 'laber'], default='uniform',